% =========================================================================
% Simple demo codes for image super-resolution via sparse representation
%
% Reference
%   J. Yang et al. Image super-resolution as sparse representation of raw
%   image patches. CVPR 2008.
%   J. Yang et al. Image super-resolution via sparse representation. IEEE 
%   Transactions on Image Processing, Vol 19, Issue 11, pp2861-2873, 2010
%
% Jianchao Yang
% ECE Department, University of Illinois at Urbana-Champaign
% For any questions, send email to jyang29@uiuc.edu
% =========================================================================

clear all; clc;

% read test image
%/////////////////////Original author code///////////////////////////////////////////
% im_l = imread('Data/Testing/input.bmp');
%//////////////////////////////////////////////////////////////////////////
%***********************Combine our work with the changed code************************
InFile_im_lt0 = 'D:\Article\BA_12CZGD21.81_23.81ChenZhouGD_20210119\ES4_ResampleTraining\S2_Dif_Post0218_PZ_Res_Clip_Res.tif';
InFile_im_ht0 = 'D:\Article\BA_12CZGD21.81_23.81ChenZhouGD_20210119\ES4_ResampleTraining\GF1C_Dif_Post0218_Res_Clip_Res.tif';
InFile_im_ltk = 'D:\Article\BA_12CZGD21.81_23.81ChenZhouGD_20210119\ES5_ResampleTesting\S2_Dif_Post0124_PZ_Res_Clip_Res.tif';
im_lt0 = imread(InFile_im_lt0);
im_ht0_1st = imread(InFile_im_ht0);
im_ltk = imread(InFile_im_ltk);
[im_ht0_2nd,Geo_im_ht0] = geotiffread(InFile_im_ht0);  %The second step is used, which utilizes the geographic information from the high-resolution image at the moment t0
info = geotiffinfo(InFile_im_ht0);                     %The second step is used

%Downsampling of the GF images
im_ht0_1st = imresize(im_ht0_1st, 0.5, 'bicubic');     %The first layer is used to reduce the high resolution image to 0.5 times its original size.
im_ht0_1st_2nd = imresize(im_ht0_1st, 0.5, 'bicubic'); %The second layer is used,for the second layer of the training dictionary.
up_scale_1st = 2.5; % The first layer is used with the aim of boosting the reconstructed image of the first layer by a factor of 2.5.
up_scale_2nd = 2;   % The second layer is used with the aim of boosting the reconstructed image of the second layer by a factor of 2.
level_1st = 1;   % The first layer is used
level_2nd = 2;   % The second layer is used
%***************************************************************************



% set parameters
lambda = 0.2;                   % sparsity regularization
overlap = 4;                    % the more overlap the better (patch size 5x5)
% up_scale = 2;                   % scaling factor, depending on the trained dictionary
% maxIter = 20;                   % if 0, do not use backprojection

% load dictionary
% load('Dictionary/D_1024_0.15_5.mat');   % ////Original author code//////

%////////////////Original author's code, color space conversion. The idea of this article is to utilize the image element values directly.//////////
% change color space, work on illuminance only
% im_l_ycbcr = rgb2ycbcr(im_l);
% im_l_y = im_l_ycbcr(:, :, 1);
% im_l_cb = im_l_ycbcr(:, :, 2);
% im_l_cr = im_l_ycbcr(:, :, 3);
%///////////////////////////////////////////////////////////////////////////

% image super-resolution based on sparse representation
%//////////////////////////Original author's code//////////////////////////////////////
% [im_h_y] = ScSR(im_l_y, 2, Dh, Dl, lambda, overlap);
% [im_h_y] = backprojection(im_h_y, im_l_y, maxIter);
%//////////////////////////////////////////////////////////////////////////

%The original author's dictionary is 2-dimensional. The dictionary of this paper is 3-dimensional and should be looped one by one.
%Start the first layer
[Dh_1st, Dl_1st] = Demo_Dictionary_Training(im_lt0, im_ht0_1st, up_scale_1st, level_1st);
OutFile_im_ltk2htk_1st = 'D:\Article\BA_12CZGD21.81_23.81ChenZhouGD_20210119\ES6_ImageHigh\FirstLevel_0124\im_htk_1st.tif';
nrow_1st = size(im_ht0_1st,1);     %row
ncol_1st = size(im_ht0_1st,2);     %col
im_ltk2htk_1st = zeros(nrow_1st,ncol_1st,4);   
for i=1:4
    [im_lt02ht0_mid_1st]= ScSR(im_lt0(:,:,i), nrow_1st, ncol_1st, Dh_1st(:,:,i), Dl_1st(:,:,i), lambda, overlap);
    [im_ltk2htk_mid_1st]= ScSR(im_ltk(:,:,i), nrow_1st, ncol_1st, Dh_1st(:,:,i), Dl_1st(:,:,i), lambda, overlap);
  
    %High-pass filtering
    im_ht0_1st = im2double(im_ht0_1st);
    im_lt02ht0_mid_1st = im2double(im_lt02ht0_mid_1st);
    im_ltk2htk_mid_1st = im2double(im_ltk2htk_mid_1st);
    im_ltk2htk_1st(:,:,i) = im_ltk2htk_mid_1st + (im_ltk2htk_mid_1st./im_lt02ht0_mid_1st).*(im_ht0_1st(:,:,i) - im_lt02ht0_mid_1st);
end
imwrite(im_ltk2htk_1st,OutFile_im_ltk2htk_1st);

%Start the second layer
[Dh_2nd, Dl_2nd] = Demo_Dictionary_Training(im_ht0_1st_2nd, im_ht0_2nd, up_scale_2nd, level_2nd);
OutFile_im_ltk2htk_2nd = 'D:\Article\BA_12CZGD21.81_23.81ChenZhouGD_20210119\ES6_ImageHigh\SecondLevel_0124\im_htk_2nd.tif';
nrow_2nd = size(im_ht0_2nd,1);    
ncol_2nd = size(im_ht0_2nd,2);     
im_ltk2htk_2nd = zeros(nrow_2nd,ncol_2nd,4);   
for i=1:4
    [im_lt02ht0_mid_2nd]= ScSR(im_ht0_1st_2nd(:,:,i), nrow_2nd, ncol_2nd, Dh_2nd(:,:,i), Dl_2nd(:,:,i), lambda, overlap);
    [im_ltk2htk_mid_2nd]= ScSR(im_ltk2htk_1st(:,:,i), nrow_2nd, ncol_2nd, Dh_2nd(:,:,i), Dl_2nd(:,:,i), lambda, overlap);
    
    %High-pass filtering
    im_ht0_2nd = im2double(im_ht0_2nd);
    im_lt02ht0_mid_2nd = im2double(im_lt02ht0_mid_2nd);
    im_ltk2htk_mid_2nd = im2double(im_ltk2htk_mid_2nd);
    im_ltk2htk_2nd(:,:,i) = im_ltk2htk_mid_2nd + (im_ltk2htk_mid_2nd./im_lt02ht0_mid_2nd).*(im_ht0_2nd(:,:,i) - im_lt02ht0_mid_2nd);
end
geotiffwrite(OutFile_im_ltk2htk_2nd,im_ltk2htk_2nd,Geo_im_ht0,'GeoKeyDirectoryTag',info.GeoTIFFTags.GeoKeyDirectoryTag);

% upscale the chrominance simply by "bicubic" 
%///////////////////////////////////////////////////////////////////////////
% [nrow, ncol] = size(im_h);
% im_h_cb = imresize(im_l_cb, [nrow, ncol], 'bicubic');
% im_h_cr = imresize(im_l_cr, [nrow, ncol], 'bicubic');
%///////////////////////////////////////////////////////////////////////////

%/////////////Original author's code, color space conversion. The idea of this article is to utilize the image element values directly.//////////
% im_h_ycbcr = zeros([nrow, ncol, 3]);
% im_h_ycbcr(:, :, 1) = im_h_y;
% im_h_ycbcr(:, :, 2) = im_h_cb;
% im_h_ycbcr(:, :, 3) = im_h_cr;
% im_h = ycbcr2rgb(uint8(im_h_ycbcr));
%///////////////////////////////////////////////////////////////////////////

%/////////////////////We don't need to calculate PSNR////////////////////
% bicubic interpolation for reference
% im_b = imresize(im_l, [nrow, ncol], 'bicubic');

% read ground truth image
% im = imread('Data/Testing/gnd.bmp');

% compute PSNR for the illuminance channel
% bb_rmse = compute_rmse(im, im_b);
% sp_rmse = compute_rmse(im, im_h);
% 
% bb_psnr = 20*log10(255/bb_rmse);
% sp_psnr = 20*log10(255/sp_rmse);
% 
% fprintf('PSNR for Bicubic Interpolation: %f dB\n', bb_psnr);
% fprintf('PSNR for Sparse Representation Recovery: %f dB\n', sp_psnr);
%///////////////////////////////////////////////////////////////////////////

% show the images
%//////////////////Direct storage without display./////////////////////////////////
% figure, imshow(im_h);
% title('Sparse Recovery');
% figure, imshow(im_b);
% title('Bicubic Interpolation');
%///////////////////////////////////////////////////////////////////////////